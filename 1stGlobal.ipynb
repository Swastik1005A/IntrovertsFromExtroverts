{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4112838b-3ccf-4a35-bcbe-8d4098ad7632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                           0\n",
      "Time_spent_Alone             0\n",
      "Stage_fear                   0\n",
      "Social_event_attendance      0\n",
      "Going_outside                0\n",
      "Drained_after_socializing    0\n",
      "Friends_circle_size          0\n",
      "Post_frequency               0\n",
      "Personality                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.read_csv(\"train.csv\")\n",
    "\n",
    "\n",
    "# Fill missing values in StageFear\n",
    "df1.loc[(df1['Stage_fear'].isnull()) & (df1['Personality'] == 'Extrovert'), 'Stage_fear'] = 'No'\n",
    "df1.loc[(df1['Stage_fear'].isnull()) & (df1['Personality'] == 'Introvert'), 'Stage_fear'] = 'Yes'\n",
    "\n",
    "\n",
    "\n",
    "df1.loc[(df1['Time_spent_Alone'].isnull()) & (df1['Personality'] == 'Introvert'), 'Time_spent_Alone'] = \\\n",
    "    np.random.uniform(4.0, 11.0, size=df1[(df1['Time_spent_Alone'].isnull()) & (df1['Personality'] == 'Introvert')].shape[0])\n",
    "\n",
    "df1.loc[(df1['Time_spent_Alone'].isnull()) & (df1['Personality'] == 'Extrovert'), 'Time_spent_Alone'] = \\\n",
    "    np.random.uniform(0.0, 3.0, size=df1[(df1['Time_spent_Alone'].isnull()) & (df1['Personality'] == 'Extrovert')].shape[0])\n",
    "\n",
    "df1.loc[(df1['Social_event_attendance'].isnull()) & (df1['Personality'] == 'Introvert'), 'Social_event_attendance'] = \\\n",
    "    np.random.uniform(0.0, 4.0, size=df1[(df1['Social_event_attendance'].isnull()) & (df1['Personality'] == 'Introvert')].shape[0])\n",
    "\n",
    "df1.loc[(df1['Social_event_attendance'].isnull()) & (df1['Personality'] == 'Extrovert'), 'Social_event_attendance'] = \\\n",
    "    np.random.uniform(5.0, 10.0, size=df1[(df1['Social_event_attendance'].isnull()) & (df1['Personality'] == 'Extrovert')].shape[0])\n",
    "\n",
    "df1.loc[(df1['Going_outside'].isnull()) & (df1['Personality'] == 'Introvert'), 'Going_outside'] = \\\n",
    "    np.random.uniform(0.0, 2.0, size=df1[(df1['Going_outside'].isnull()) & (df1['Personality'] == 'Introvert')].shape[0])\n",
    "\n",
    "df1.loc[(df1['Going_outside'].isnull()) & (df1['Personality'] == 'Extrovert'), 'Going_outside'] = \\\n",
    "    np.random.uniform(3.0, 7.0, size=df1[(df1['Going_outside'].isnull()) & (df1['Personality'] == 'Extrovert')].shape[0])\n",
    "\n",
    "df1.loc[(df1['Drained_after_socializing'].isnull()) & (df1['Personality'] == 'Extrovert'), 'Drained_after_socializing'] = 'No'\n",
    "df1.loc[(df1['Drained_after_socializing'].isnull()) & (df1['Personality'] == 'Introvert'), 'Drained_after_socializing'] = 'Yes'\n",
    "\n",
    "df1.loc[(df1['Friends_circle_size'].isnull()) & (df1['Personality'] == 'Introvert'), 'Friends_circle_size'] = \\\n",
    "    np.random.uniform(0.0, 4.0, size=df1[(df1['Friends_circle_size'].isnull()) & (df1['Personality'] == 'Introvert')].shape[0])\n",
    "\n",
    "df1.loc[(df1['Friends_circle_size'].isnull()) & (df1['Personality'] == 'Extrovert'), 'Friends_circle_size'] = \\\n",
    "    np.random.uniform(5.0, 15.0, size=df1[(df1['Friends_circle_size'].isnull()) & (df1['Personality'] == 'Extrovert')].shape[0])\n",
    "\n",
    "df1.loc[(df1['Post_frequency'].isnull()) & (df1['Personality'] == 'Introvert'), 'Post_frequency'] = \\\n",
    "    np.random.uniform(0.0, 5.0, size=df1[(df1['Post_frequency'].isnull()) & (df1['Personality'] == 'Introvert')].shape[0])\n",
    "\n",
    "df1.loc[(df1['Post_frequency'].isnull()) & (df1['Personality'] == 'Extrovert'), 'Post_frequency'] = \\\n",
    "    np.random.uniform(6.0, 10.0, size=df1[(df1['Post_frequency'].isnull()) & (df1['Personality'] == 'Extrovert')].shape[0])\n",
    "\n",
    "# df1['Stage_fear'] = df1['Stage_fear'].astype(float64)\n",
    "# df1['Drained_after_socializing'] = df1['Drained_after_socializing'].astype(float64)\n",
    "\n",
    "df1['Drained_after_socializing'] = df1['Drained_after_socializing'].map({'Yes': 1.0, 'No': 0.0})\n",
    "df1['Stage_fear'] = df1['Stage_fear'].map({'Yes': 1.0, 'No': 0.0})\n",
    "df1['Personality'] = df1['Personality'].map({'Introvert': 1.0, 'Extrovert': 0.0})\n",
    "\n",
    "df1['Time_spent_Alone'] = df1['Time_spent_Alone'].round(0)\n",
    "df1['Social_event_attendance'] = df1['Social_event_attendance'].round(0)\n",
    "df1['Going_outside'] = df1['Going_outside'].round(0)\n",
    "df1['Drained_after_socializing'] = df1['Drained_after_socializing'].round(0)\n",
    "df1['Friends_circle_size'] = df1['Friends_circle_size'].round(0)\n",
    "df1['Post_frequency'] = df1['Post_frequency'].round(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(df1.isnull().sum())\n",
    "df1.to_csv(\"train_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c7552a-134a-4432-b3b1-720e2bb6ba9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                           0\n",
      "Time_spent_Alone             0\n",
      "Stage_fear                   0\n",
      "Social_event_attendance      0\n",
      "Going_outside                0\n",
      "Drained_after_socializing    0\n",
      "Friends_circle_size          0\n",
      "Post_frequency               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df2 = pd.read_csv(\"test.csv\")\n",
    "\n",
    "\n",
    "df2.loc[(df2['Time_spent_Alone'].isnull()) & (df2['Stage_fear'] == 'Yes'), 'Time_spent_Alone'] = \\\n",
    "    np.random.uniform(0.0, 3.0, size=df2[(df2['Time_spent_Alone'].isnull()) & (df2['Stage_fear'] == 'Yes')].shape[0])\n",
    "\n",
    "df2.loc[(df2['Time_spent_Alone'].isnull()) & (df2['Stage_fear'] == 'No'), 'Time_spent_Alone'] = \\\n",
    "    np.random.uniform(4.0, 11.0, size=df2[(df2['Time_spent_Alone'].isnull()) & (df2['Stage_fear'] == 'No')].shape[0])\n",
    "\n",
    "df2.loc[(df2['Time_spent_Alone'].isnull()) & (df2['Social_event_attendance'] >= 0.0) & (df2['Social_event_attendance'] <= 4.0), 'Time_spent_Alone'] = \\\n",
    "    np.random.uniform(0.0, 3.0, size=df2[(df2['Time_spent_Alone'].isnull()) & (df2['Social_event_attendance'] >= 0.0) & (df2['Social_event_attendance'] <= 4.0)].shape[0])\n",
    "\n",
    "df2.loc[(df2['Time_spent_Alone'].isnull()) & (df2['Social_event_attendance'] > 4.0) & (df2['Social_event_attendance'] <= 8.0), 'Time_spent_Alone'] = \\\n",
    "    np.random.uniform(4.0, 11.0, size=df2[(df2['Time_spent_Alone'].isnull()) & (df2['Social_event_attendance'] > 4.0) & (df2['Social_event_attendance'] <= 8.0)].shape[0])\n",
    "\n",
    "df2.loc[(df2['Time_spent_Alone'].isnull()) & (df2['Going_outside'] >= 0.0) & (df2['Going_outside'] <= 2.0), 'Time_spent_Alone'] = \\\n",
    "    np.random.uniform(0.0, 3.0, size=df2[(df2['Time_spent_Alone'].isnull()) & (df2['Going_outside'] >= 0.0) & (df2['Going_outside'] <= 2.0)].shape[0])\n",
    "\n",
    "df2.loc[(df2['Time_spent_Alone'].isnull()) & (df2['Going_outside'] >= 3.0) & (df2['Going_outside'] <= 7.0), 'Time_spent_Alone'] = \\\n",
    "    np.random.uniform(4.0, 11.0, size=df2[(df2['Time_spent_Alone'].isnull()) & (df2['Going_outside'] >= 3.0) & (df2['Going_outside'] <= 7.0)].shape[0])\n",
    "\n",
    "\n",
    "df2['Time_spent_Alone'] = df2['Time_spent_Alone'].round(0)\n",
    "\n",
    "\n",
    "df2.loc[(df2['Drained_after_socializing'].isnull()) & (df2['Time_spent_Alone'] <= 3.0), 'Drained_after_socializing'] = 'No'\n",
    "df2.loc[(df2['Drained_after_socializing'].isnull()) & (df2['Time_spent_Alone'] >= 4.0), 'Drained_after_socializing'] = 'Yes'\n",
    "\n",
    "\n",
    "df2.loc[(df2['Stage_fear'].isnull()) & (df2['Drained_after_socializing'] == 'No'), 'Stage_fear'] = 'No'\n",
    "df2.loc[(df2['Stage_fear'].isnull()) & (df2['Drained_after_socializing'] == 'Yes'), 'Stage_fear'] = 'Yes'\n",
    "\n",
    "df2.loc[\n",
    "    (df2['Social_event_attendance'].isnull()) & (df2['Stage_fear'] == 'No'),\n",
    "    'Social_event_attendance'\n",
    "] = np.random.randint(4, 11, size=df2[(df2['Social_event_attendance'].isnull()) & (df2['Stage_fear'] == 'No')].shape[0])\n",
    "\n",
    "df2.loc[\n",
    "    (df2['Social_event_attendance'].isnull()) & (df2['Stage_fear'] == 'Yes'),\n",
    "    'Social_event_attendance'\n",
    "] = np.random.randint(0, 4, size=df2[(df2['Social_event_attendance'].isnull()) & (df2['Stage_fear'] == 'Yes')].shape[0])\n",
    "\n",
    "df2.loc[\n",
    "    (df2['Going_outside'].isnull()) & (df2['Stage_fear'] == 'No'),\n",
    "    'Going_outside'\n",
    "] = np.random.randint(3, 7, size=df2[(df2['Going_outside'].isnull()) & (df2['Stage_fear'] == 'No')].shape[0])\n",
    "\n",
    "df2.loc[\n",
    "    (df2['Going_outside'].isnull()) & (df2['Stage_fear'] == 'Yes'),\n",
    "    'Going_outside'\n",
    "] = np.random.randint(0, 2, size=df2[(df2['Going_outside'].isnull()) & (df2['Stage_fear'] == 'Yes')].shape[0])\n",
    "\n",
    "df2.loc[\n",
    "    (df2['Friends_circle_size'].isnull()) & (df2['Stage_fear'] == 'No'),\n",
    "    'Friends_circle_size'\n",
    "] = np.random.randint(6, 15, size=df2[(df2['Friends_circle_size'].isnull()) & (df2['Stage_fear'] == 'No')].shape[0])\n",
    "\n",
    "df2.loc[\n",
    "    (df2['Friends_circle_size'].isnull()) & (df2['Stage_fear'] == 'Yes'),\n",
    "    'Friends_circle_size'\n",
    "] = np.random.randint(0, 5, size=df2[(df2['Friends_circle_size'].isnull()) & (df2['Stage_fear'] == 'Yes')].shape[0])\n",
    "\n",
    "df2.loc[\n",
    "    (df2['Post_frequency'].isnull()) & (df2['Stage_fear'] == 'No'),\n",
    "    'Post_frequency'\n",
    "] = np.random.randint(3, 10, size=df2[(df2['Post_frequency'].isnull()) & (df2['Stage_fear'] == 'No')].shape[0])\n",
    "\n",
    "df2.loc[\n",
    "    (df2['Post_frequency'].isnull()) & (df2['Stage_fear'] == 'Yes'),\n",
    "    'Post_frequency'\n",
    "] = np.random.randint(0, 3, size=df2[(df2['Post_frequency'].isnull()) & (df2['Stage_fear'] == 'Yes')].shape[0])\n",
    "\n",
    "\n",
    "# Final Fallbacks (optional but safe)\n",
    "# df2['Time_spent_Alone'].fillna(round(df2['Time_spent_Alone'].median(), 0), inplace=True)\n",
    "# df2['Drained_after_socializing'].fillna(df2['Drained_after_socializing'].mode()[0], inplace=True)\n",
    "# df2['Stage_fear'].fillna(df2['Stage_fear'].mode()[0], inplace=True)\n",
    "df2['Drained_after_socializing'] = df2['Drained_after_socializing'].map({'Yes': 1.0, 'No': 0.0})\n",
    "df2['Stage_fear'] = df2['Stage_fear'].map({'Yes': 1.0, 'No': 0.0})\n",
    "\n",
    "\n",
    "print(df2.isnull().sum())\n",
    "\n",
    "df2.to_csv(\"test_cleaned.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b660caaa-c547-43ab-a509-70f7064748a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Validation Accuracy: 97.41 %\n",
      "✅ Predictions saved to submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\projectenv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:42:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "#MODEL TRAINING TIME\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ✅ Load cleaned train and test sets\n",
    "df1 = pd.read_csv(\"train_cleaned.csv\")\n",
    "df2 = pd.read_csv(\"test_cleaned.csv\")\n",
    "\n",
    "# ✅ Separate features and target in training data\n",
    "X = df1.drop(columns=[\"id\", \"Personality\"])\n",
    "y = df1[\"Personality\"]\n",
    "\n",
    "# ✅ Optional: Split train into train/validation to check accuracy\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ✅ Train the model\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ✅ Predict on validation data\n",
    "y_pred_val = model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred_val)\n",
    "print(\"✅ Validation Accuracy:\", round(accuracy * 100, 2), \"%\")\n",
    "\n",
    "# ✅ Now predict on test data\n",
    "X_test = df2.drop(columns=[\"id\"])\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# ✅ Map predicted values to labels\n",
    "label_map = {0: \"Extrovert\", 1: \"Introvert\"}\n",
    "y_pred_test_labels = pd.Series(y_pred_test).map(label_map)\n",
    "\n",
    "# ✅ Create a submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": df2[\"id\"],\n",
    "    \"Personality\": y_pred_test_labels\n",
    "})\n",
    "\n",
    "# ✅ Save to CSV\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"✅ Predictions saved to submission.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5274144-3ca8-4554-9a2f-a107f986edf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
